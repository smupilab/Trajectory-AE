{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Taejin1221/MachineLearning/blob/master/TrajectoryAugmentation/Augmentation_U_net(3x3).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dGc8Ai1fzHN"
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_ouXXLsUSCzz"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8_SQQfcF1ip3"
   },
   "outputs": [],
   "source": [
    "import cv2, os, glob, random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMx_5oTgUpax"
   },
   "source": [
    "# Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hTFEUhLfSqCF"
   },
   "outputs": [],
   "source": [
    "import random, cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 빈 캔버스 만들기\n",
    "def init() -> np.array: \n",
    "    blank = np.zeros([512,512],dtype=np.uint8)\n",
    "    blank.fill(0)\n",
    "    blank = cv2.resize(blank,(512,512))\n",
    "\n",
    "    return blank\n",
    "\n",
    "# Convert 0-1 Images into 0-255 Image\n",
    "def drawNp( img: np.array, dotForm ) -> np.array:\n",
    "    '''\n",
    "    dotForm = 0 : 1x1 dot\n",
    "    dotForm = 1 : crosshead (3x3)\n",
    "    dotForm = 2 : 3x3 dot\n",
    "    '''\n",
    "    blank = init()\n",
    "\n",
    "    rowDiff = [ [ 0 ], [ -1, 0, 0, 0, 1 ], [ -1, -1, -1, 0, 0, 0, 1, 1, 1 ] ]\n",
    "    colDiff = [ [ 0 ], [ 0, -1, 0, 1, 0 ], [ -1, 0, 1, -1, 0, 1, -1, 0, 1 ] ]\n",
    "\n",
    "    for i in range( 0, img.shape[0] ):\n",
    "        for j in range( 0, img.shape[1] ):\n",
    "            if img[i][j] == 1 :\n",
    "                for rr, cc in zip( rowDiff[dotForm], colDiff[dotForm] ):\n",
    "                    newRow, newCol = i + rr, j + cc\n",
    "                    if ( 0 <= newRow < img.shape[0] and 0 <= newCol < img.shape[1] ):\n",
    "                        blank[newRow][newCol] = 255\n",
    "\n",
    "    return blank\n",
    "\n",
    "\n",
    "# Convert csv File to Image\n",
    "def map2Image(min_max: tuple, dot: int, csv_file: pd.DataFrame) -> np.array:\n",
    "    inputImage = np.zeros([512,512], dtype=np.uint8)\n",
    "\n",
    "    minX, minY, maxX, maxY = min_max\n",
    "\n",
    "    for i in range(0,csv_file.shape[0]):\n",
    "        x = csv_file.loc[i][0]\n",
    "        y = csv_file.loc[i][1]\n",
    "\n",
    "        # Print Dot\n",
    "        mapX = int(round(np.interp(x,[minX,maxX],[0,500])))\n",
    "        mapY = int(round(np.interp(y,[minY,maxY],[0,500])))\n",
    "        inputImage[mapX][mapY] = 1\n",
    "\n",
    "    outputImage = drawNp(inputImage, dot)\n",
    "\n",
    "    rotImage = np.rot90(outputImage)\n",
    "\n",
    "    return rotImage\n",
    "\n",
    "\n",
    "# Convert csv File to Image with Noise\n",
    "def map2Image_noise(min_max: tuple, dot: int, csv_file: pd.DataFrame) -> np.array:\n",
    "    inputImage = np.zeros([512,512], dtype=np.uint8)\n",
    "\n",
    "    minX, minY, maxX, maxY = min_max\n",
    "\n",
    "    randomList = set()\n",
    "    while len(randomList) < int(csv_file.shape[0] / 7):\n",
    "        randomList.add(random.randint(0,csv_file.shape[0]))\n",
    "\n",
    "    randomList=list(randomList)\n",
    "    dicisionList = [1,-1]\n",
    "\n",
    "    for i in range(0, csv_file.shape[0]):\n",
    "        try:\n",
    "            # Generate Noise\n",
    "            randomList.index(i)\n",
    "\n",
    "            r = random.uniform((minX - maxX) / 40,(minX - maxX) / 20)\n",
    "            D = random.choice(dicisionList)\n",
    "\n",
    "            x = csv_file.loc[i][0] - (D * r)\n",
    "            y = csv_file.loc[i][1] - (D * r)\n",
    "\n",
    "            # Paint dot\n",
    "            mapX = int(round(np.interp(x,[minX,maxX],[0,500])))\n",
    "            mapY = int(round(np.interp(y,[minY,maxY], [0,500])))\n",
    "            inputImage[mapX][mapY] = 1\n",
    "\n",
    "        except:\n",
    "            x = csv_file.loc[i][0]\n",
    "            y = csv_file.loc[i][1]\n",
    "\n",
    "            mapX = int(round(np.interp(x,[minX,maxX],[0,500])))\n",
    "            mapY = int(round(np.interp(y,[minY,maxY], [0,500])))\n",
    "            inputImage[mapX][mapY] = 1\n",
    "\n",
    "\n",
    "    outputImage = drawNp(inputImage, dot)\n",
    "\n",
    "    rotImage = np.rot90(outputImage)\n",
    "\n",
    "    return rotImage\n",
    "\n",
    "\n",
    "def map2Image_remove(min_max: tuple, dot: int, csv_file: pd.DataFrame) -> np.array:\n",
    "    inputImage = np.zeros([512,512], dtype=np.uint8)\n",
    "\n",
    "    minX, minY, maxX, maxY = min_max\n",
    "\n",
    "    removeList = [ ]\n",
    "    fileNum = csv_file.shape[0]\n",
    "    for _ in range( int( fileNum * 0.5 ) ):\n",
    "        idx = random.randint( 0, fileNum )\n",
    "        while ( idx in removeList ):\n",
    "            idx = random.randint( 0, fileNum )\n",
    "\n",
    "        removeList.append( idx )\n",
    "\n",
    "    for i in range(0, fileNum):\n",
    "        if ( i in removeList ):\n",
    "            continue\n",
    "\n",
    "        x = csv_file.loc[i][0]\n",
    "        y = csv_file.loc[i][1]\n",
    "\n",
    "        # Print Dot\n",
    "        mapX = int(round(np.interp(x,[minX,maxX],[0,500])))\n",
    "        mapY = int(round(np.interp(y,[minY,maxY],[0,500])))\n",
    "        inputImage[mapX][mapY] = 1\n",
    "\n",
    "    outputImage = drawNp(inputImage, dot)\n",
    "\n",
    "    rotImage = np.rot90(outputImage)\n",
    "\n",
    "    return rotImage\n",
    "\n",
    "\n",
    "# Return Max and Min X,Y Coordinate Value of file\n",
    "def coorMaxMin(file: pd.DataFrame) -> (float, float, float, float):\n",
    "    minX, minY = (file.loc[0][0], file.loc[0][1])\n",
    "    maxX, maxY = (file.loc[0][0], file.loc[0][1])\n",
    "    for i in range(0,file.shape[0]):\n",
    "        x = file.loc[i][0]\n",
    "        y = file.loc[i][1]\n",
    "        if x > maxX :\n",
    "            maxX = x\n",
    "        if x < minX :\n",
    "            minX = x\n",
    "        if y > maxY :\n",
    "            maxY = y\n",
    "        if y < minY :\n",
    "            minY = y\n",
    "    return minX, minY, maxX, maxY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFQ6cclGU7Yr"
   },
   "source": [
    "# Loading Data and Conveting into Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "m0nZb6kK0PlK"
   },
   "outputs": [],
   "source": [
    "dataDir = \"/Users/grape/GitHub/Trajectory_Data/VirtualData/only_csv/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-27cQD6F09tn"
   },
   "outputs": [],
   "source": [
    "SIZE = 512\n",
    "\n",
    "os.chdir( dataDir )\n",
    "files = glob.glob( '*csv' )\n",
    "\n",
    "trainSize = int( len( files ) * 0.8 )\n",
    "trainFiles, testFiles = files[ : trainSize], files[trainSize : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJZV1FRLYDey",
    "outputId": "9ef17824-cae5-4a49-eb79-1e028d0c0daf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "print( len( files ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HUFGfRiSVLrQ"
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = [ ], [ ]\n",
    "for file in trainFiles:\n",
    "\tcsv_file = pd.read_csv( file, names = [ 'lat', 'long', 'num' ], header = None )\n",
    "\tmaxmin = coorMaxMin( csv_file )\n",
    "\tX_train.append( map2Image_remove( maxmin, 2, csv_file ) )\n",
    "\tY_train.append( map2Image( maxmin, 2, csv_file ) )\n",
    "\n",
    "X_test = [ ]\n",
    "for file in testFiles:\n",
    "\tcsv_file = pd.read_csv( file, names = [ 'lat', 'long', 'num' ], header = None )\n",
    "\tmaxmin = coorMaxMin( csv_file )\n",
    "\tX_test.append( map2Image_remove( maxmin, 2, csv_file ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BqPbB1oD2WDP",
    "outputId": "3eac27ff-13ef-4237-ec6d-9eff3f135803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 512, 512)\n",
      "(52, 512, 512)\n",
      "(14, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(Y_train))\n",
    "print(np.shape(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oyrXSyixcWoE",
    "outputId": "f9ec79d7-0766-4c6b-beff-84a3fea09035"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-facde09b8aa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "cv2_imshow( X_train[0] )\n",
    "cv2_imshow( Y_train[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sz4t7yMfZk1"
   },
   "source": [
    "## Resize Images for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4wgWP2k18C0",
    "outputId": "19f45488-3cbf-4697-be1d-6f27bee3e5d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 512, 512) (52, 512, 512) (14, 512, 512)\n",
      "train shape (X, Y): ((52, 512, 512, 1),(52, 512, 512, 1))\n",
      "test shape (X): ((14, 512, 512, 1))\n"
     ]
    }
   ],
   "source": [
    "## Resize Images for CNN ##\n",
    "X_train, Y_train = np.array( X_train ), np.array( Y_train )\n",
    "X_test = np.array( X_test )\n",
    "\n",
    "X_train = X_train.astype( 'float32' ) / 255.\n",
    "Y_train = Y_train.astype( 'float32' ) / 255.\n",
    "X_test = X_test.astype( 'float32' ) / 255.\n",
    "\n",
    "print( X_train.shape, Y_train.shape, X_test.shape )\n",
    "\n",
    "X_train = np.reshape( X_train, ( len( X_train ), SIZE, SIZE, 1 ) )\n",
    "Y_train = np.reshape( Y_train, ( len( Y_train ), SIZE, SIZE, 1 ) )\n",
    "X_test = np.reshape( X_test, ( len( X_test ), SIZE, SIZE, 1 ) )\n",
    "\n",
    "print( 'train shape (X, Y): ({},{})'.format( X_train.shape, Y_train.shape ) )\n",
    "print( 'test shape (X): ({})'.format( X_test.shape ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyEZta-aVel3"
   },
   "source": [
    "# Constructing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "y6phmNBJVjer"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "q3Gu0XeM4bJw"
   },
   "outputs": [],
   "source": [
    " ## Hyper Parameter ##\n",
    "acti, pad = 'relu', 'same'\n",
    "\n",
    "## Input Image ##\n",
    "input_img = layers.Input(shape=(512, 512, 1))\n",
    "\n",
    "# Encoding #\n",
    "conv1 = layers.Conv2D( 128, ( 3, 3 ), activation = 'relu', padding = 'same' )( input_img )\n",
    "pool1 = layers.MaxPooling2D( ( 2, 2 ), padding = 'same' )( conv1 )\n",
    "\n",
    "conv2 = layers.Conv2D( 64, ( 3, 3 ),  activation = 'relu', padding = 'same' )( pool1 )\n",
    "pool2 = layers.MaxPooling2D( ( 2, 2 ), padding = 'same' )( conv2 )\n",
    "\n",
    "conv3 = layers.Conv2D( 32, ( 3, 3 ), activation = 'relu', padding = 'same' )( pool2 )\n",
    "pool3 = layers.MaxPooling2D( ( 2, 2 ), padding = 'same' )( conv3 )\n",
    "\n",
    "\n",
    "# Decoding #\n",
    "conv4 = layers.Conv2D( 32, ( 3, 3 ), activation = 'relu', padding = 'same' )( pool3 )\n",
    "up1 = layers.UpSampling2D( ( 2, 2 ) )( conv4 )\n",
    "\n",
    "merge1 = layers.concatenate([conv3,up1])\n",
    "conv5 = layers.Conv2D( 64, ( 3, 3 ), activation = 'relu', padding = 'same' )( merge1 )\n",
    "up2 = layers.UpSampling2D( ( 2, 2 ) )( conv5 )\n",
    "\n",
    "#merge2 = concatenate([conv2,up2])\n",
    "conv6 = layers.Conv2D( 128, ( 3, 3 ), activation = 'relu', padding = 'same' )( up2 )\n",
    "up3 = layers.UpSampling2D( ( 2, 2 ) )( conv6 )\n",
    "\n",
    "\n",
    "decoded = layers.Conv2D( 1, ( 3, 3 ), activation = 'sigmoid', padding = 'same' )( up3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haPwD0y8fnMN"
   },
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "APBl4yDl4q2c",
    "outputId": "ed97713d-0fbf-4526-e7c6-adf260dd7139"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 128 1280        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 128 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 73792       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 32) 18464       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 32)   9248        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 128, 128, 32) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128, 128, 64) 0           conv2d_2[0][0]                   \n",
      "                                                                 up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 64) 36928       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 256, 256, 64) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 256, 128 73856       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 512, 512, 128 0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 512, 512, 1)  1153        up_sampling2d_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 214,721\n",
      "Trainable params: 214,721\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Compile\n",
    "Unet = keras.Model(input_img, decoded)\n",
    "Unet.summary()\n",
    "\n",
    "Unet.compile( optimizer = 'adam', loss = 'binary_crossentropy', metrics = [ 'acc' ] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gB6KVEIWfrM5"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_vm7-n1406I",
    "outputId": "21c69779-2e39-4f94-da3c-0bc51ffbb001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52 samples\n",
      "Epoch 1/30\n",
      "52/52 [==============================] - 93s 2s/sample - loss: 0.6595 - acc: 0.9537\n",
      "Epoch 2/30\n",
      "52/52 [==============================] - 92s 2s/sample - loss: 0.2373 - acc: 0.9927\n",
      "Epoch 3/30\n",
      "52/52 [==============================] - 91s 2s/sample - loss: 0.1109 - acc: 0.9927\n",
      "Epoch 4/30\n",
      "52/52 [==============================] - 92s 2s/sample - loss: 0.0596 - acc: 0.9927\n",
      "Epoch 5/30\n",
      "52/52 [==============================] - 91s 2s/sample - loss: 0.0360 - acc: 0.9927\n",
      "Epoch 6/30\n",
      "52/52 [==============================] - 89s 2s/sample - loss: 0.0255 - acc: 0.9927\n",
      "Epoch 7/30\n",
      "52/52 [==============================] - 90s 2s/sample - loss: 0.0227 - acc: 0.9927\n",
      "Epoch 8/30\n",
      "52/52 [==============================] - 90s 2s/sample - loss: 0.0216 - acc: 0.9927\n",
      "Epoch 9/30\n",
      "52/52 [==============================] - 90s 2s/sample - loss: 0.0207 - acc: 0.9927\n",
      "Epoch 10/30\n",
      "52/52 [==============================] - 86s 2s/sample - loss: 0.0199 - acc: 0.9927\n",
      "Epoch 11/30\n",
      "52/52 [==============================] - 96s 2s/sample - loss: 0.0193 - acc: 0.9927\n",
      "Epoch 12/30\n",
      "52/52 [==============================] - 89s 2s/sample - loss: 0.0188 - acc: 0.9927\n",
      "Epoch 13/30\n",
      "52/52 [==============================] - 94s 2s/sample - loss: 0.0182 - acc: 0.9928\n",
      "Epoch 14/30\n",
      "52/52 [==============================] - 91s 2s/sample - loss: 0.0175 - acc: 0.9935\n",
      "Epoch 15/30\n",
      "52/52 [==============================] - 90s 2s/sample - loss: 0.0167 - acc: 0.9946\n",
      "Epoch 16/30\n",
      "52/52 [==============================] - 90s 2s/sample - loss: 0.0160 - acc: 0.9949\n",
      "Epoch 17/30\n",
      "52/52 [==============================] - 95s 2s/sample - loss: 0.0153 - acc: 0.9950\n",
      "Epoch 18/30\n",
      "52/52 [==============================] - 608s 12s/sample - loss: 0.0149 - acc: 0.9950\n",
      "Epoch 19/30\n",
      "52/52 [==============================] - 100s 2s/sample - loss: 0.0145 - acc: 0.9950\n",
      "Epoch 20/30\n",
      "52/52 [==============================] - 89s 2s/sample - loss: 0.0141 - acc: 0.9951\n",
      "Epoch 21/30\n",
      "52/52 [==============================] - 84s 2s/sample - loss: 0.0136 - acc: 0.9954\n",
      "Epoch 22/30\n",
      "52/52 [==============================] - 89s 2s/sample - loss: 0.0139 - acc: 0.9951\n",
      "Epoch 23/30\n",
      "52/52 [==============================] - 96s 2s/sample - loss: 0.0137 - acc: 0.9952\n",
      "Epoch 24/30\n",
      "52/52 [==============================] - 103s 2s/sample - loss: 0.0132 - acc: 0.9955\n",
      "Epoch 25/30\n",
      "52/52 [==============================] - 116s 2s/sample - loss: 0.0129 - acc: 0.9955\n",
      "Epoch 26/30\n",
      "52/52 [==============================] - 101s 2s/sample - loss: 0.0129 - acc: 0.9955\n",
      "Epoch 27/30\n",
      "52/52 [==============================] - 100s 2s/sample - loss: 0.0128 - acc: 0.9955\n",
      "Epoch 28/30\n",
      "52/52 [==============================] - 93s 2s/sample - loss: 0.0126 - acc: 0.9957\n",
      "Epoch 29/30\n",
      "52/52 [==============================] - 91s 2s/sample - loss: 0.0123 - acc: 0.9958\n",
      "Epoch 30/30\n",
      "52/52 [==============================] - 93s 2s/sample - loss: 0.0123 - acc: 0.9957\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 30\n",
    "BATCH = 10\n",
    "SHUFFLE = True\n",
    "\n",
    "history = Unet.fit( X_train, Y_train, epochs = EPOCH, batch_size = BATCH, shuffle = SHUFFLE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pNBCURHV5aQ6"
   },
   "outputs": [],
   "source": [
    "decoded_img = Unet.predict( X_test  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tmJ5u-WxWlaM",
    "outputId": "ab158625-6327-430b-8255-75eaaf4c3177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(decoded_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Im3KVngKfufW"
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "psGePCCd5SCc",
    "outputId": "0b34d959-9d75-4697-9898-3eb1c5d75437"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10\n",
    "plt.figure( figsize = ( 20, 4 ) )\n",
    "for i in range( n ):\n",
    "\tax = plt.subplot( 2, n, i + 1 )\n",
    "\tplt.imshow( X_test[i].reshape( SIZE, SIZE) )\n",
    "\tplt.gray()\n",
    "\n",
    "\tax.get_xaxis().set_visible( False )\n",
    "\tax.get_yaxis().set_visible( False )\n",
    "\n",
    "\tax = plt.subplot( 2, n, n + i + 1 )\n",
    "\tplt.imshow( decoded_img[i].reshape( SIZE, SIZE))\n",
    "\tplt.gray()\n",
    "\n",
    "\tax.get_xaxis().set_visible( False )\n",
    "\tax.get_yaxis().set_visible( False )\n",
    "\n",
    "plt.savefig( 'Result.png', dpi = 300 )\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Augmentation_U-net(3x3).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
