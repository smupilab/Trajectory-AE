{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import convertImage\n",
    "\n",
    "SIZE = 512\n",
    "\n",
    "trajectoryAugmentataionDir = '/Users/grape/GitHub/Trajectory-Augmentation/'\n",
    "trajectoryDataDir = '/Users/grape/GitHub/Trajectory_Data/'\n",
    "\n",
    "currDir = trajectoryAugmentataionDir + 'script/'\n",
    "dataDir = trajectoryDataDir + 'VirtualData/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir( dataDir )\n",
    "files = glob.glob( '*csv' )\n",
    "\n",
    "trainSize = int( len( files ) * 0.8 )\n",
    "trainFiles, testFiles = files[ : trainSize], files[trainSize : ]\n",
    "\n",
    "X_train, Y_train = [ ], [ ]\n",
    "for file in trainFiles:\n",
    "\tcsv_file = pd.read_csv( file, names = [ 'lat', 'long', 'num' ], header = None )\n",
    "\tmaxmin = convertImage.coorMaxMin( csv_file )\n",
    "\tX_train.append( convertImage.map2Image_remove( *maxmin, csv_file ) )\n",
    "\tY_train.append( convertImage.map2Image( *maxmin, csv_file ) )\n",
    "\n",
    "X_test = [ ]\n",
    "for file in testFiles:\n",
    "\tcsv_file = pd.read_csv( file, names = [ 'lat', 'long', 'num' ], header = None )\n",
    "\tmaxmin = convertImage.coorMaxMin( csv_file )\n",
    "\tX_test.append( convertImage.map2Image_remove( *maxmin, csv_file ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = np.array( X_train ), np.array( Y_train )\n",
    "X_test = np.array( X_test )\n",
    "\n",
    "X_train = X_train / 255.\n",
    "Y_train = Y_train / 255.\n",
    "X_test = X_test / 255.\n",
    "\n",
    "X_train = np.reshape( X_train, ( len( X_train ), SIZE, SIZE, 1 ) )\n",
    "Y_train = np.reshape( Y_train, ( len( Y_train ), SIZE, SIZE, 1 ) )\n",
    "X_test = np.reshape( X_test, ( len( X_test ), SIZE, SIZE, 1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf; tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def ComputeLatent( x ):\n",
    "\tmu, sigma = x\n",
    "\teps = K.random_normal( shape = ( K.shape( mu )[0], K.int_shape( mu )[1] ) )\n",
    "\n",
    "\treturn mu + K.exp( sigma / 2 ) * eps\n",
    "\n",
    "latent = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/grape/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "encoder_input = layers.Input( shape = ( SIZE, SIZE, 1 ) )\n",
    "encoder_conv = layers.Conv2D( 128, 3, 2, 'same', activation = 'relu' )( encoder_input )\n",
    "encoder_conv = layers.Conv2D( 256, 3, 2, 'same', activation = 'relu' )( encoder_conv )\n",
    "\n",
    "encoder = layers.Flatten()( encoder_conv )\n",
    "\n",
    "mu = layers.Dense( latent )( encoder )\n",
    "sigma = layers.Dense( latent )( encoder )\n",
    "\n",
    "latent_space = layers.Lambda( ComputeLatent, output_shape = ( latent, ) )( [ mu, sigma ] )\n",
    "\n",
    "conv_shape = K.int_shape( encoder_conv )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = layers.Input( shape = ( latent, ) )\n",
    "\n",
    "units = conv_shape[1] * conv_shape[2] * conv_shape[3]\n",
    "decoder = layers.Dense( units, 'relu' )( decoder_input )\n",
    "decoder = layers.Reshape( ( conv_shape[1], conv_shape[2], conv_shape[3] ) )( decoder )\n",
    "\n",
    "decoder_conv = layers.Conv2DTranspose( 256, 3, 2, 'same', activation = 'relu' )( decoder )\n",
    "decoder_conv = layers.Conv2DTranspose( 128, 3, 2, 'same', activation = 'relu' )( decoder_conv )\n",
    "decoder_output = layers.Conv2DTranspose( 1, 3, padding = 'same', activation = 'sigmoid' )( decoder_conv )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 128 1280        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 256 295168      conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 4194304)      0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            8388610     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            8388610     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 2)            0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 17,073,668\n",
      "Trainable params: 17,073,668\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4194304)           12582912  \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 256, 256, 256)     590080    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 512, 512, 128)     295040    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 512, 512, 1)       1153      \n",
      "=================================================================\n",
      "Total params: 13,469,185\n",
      "Trainable params: 13,469,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"VAE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 512, 512, 1)]     0         \n",
      "_________________________________________________________________\n",
      "Encoder (Model)              (None, 2)                 17073668  \n",
      "_________________________________________________________________\n",
      "Decoder (Model)              (None, 512, 512, 1)       13469185  \n",
      "=================================================================\n",
      "Total params: 30,542,853\n",
      "Trainable params: 30,542,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = keras.models.Model( encoder_input, latent_space, name = 'Encoder' )\n",
    "decoder = keras.models.Model( decoder_input, decoder_output, name = 'Decoder' )\n",
    "\n",
    "vae = keras.models.Model( encoder_input, decoder( encoder( encoder_input ) ), name = 'VAE' )\n",
    "\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_Reconstruction_Loss( true, pred ):\n",
    "\treconstruction_loss = keras.losses.binary_crossentropy( K.flatten( true ), K.flatten( pred ) ) * SIZE * SIZE\n",
    "\n",
    "\tkl_loss = 1 + sigma - K.square( mu ) - K.exp( sigma )\n",
    "\tkl_loss = K.sum( kl_loss, axis = -1 )\n",
    "\tkl_loss *= -0.5\n",
    "\n",
    "\treturn K.mean( reconstruction_loss + kl_loss )\n",
    "\n",
    "vae.compile( 'adam', KL_Reconstruction_Loss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52 samples\n",
      "Epoch 1/30\n",
      "52/52 [==============================] - 79s 2s/sample - loss: nan\n",
      "Epoch 2/30\n",
      "52/52 [==============================] - 82s 2s/sample - loss: nan\n",
      "Epoch 3/30\n",
      "52/52 [==============================] - 77s 1s/sample - loss: nan\n",
      "Epoch 4/30\n",
      "52/52 [==============================] - 71s 1s/sample - loss: nan\n",
      "Epoch 5/30\n",
      "52/52 [==============================] - 80s 2s/sample - loss: nan\n",
      "Epoch 6/30\n",
      "52/52 [==============================] - 74s 1s/sample - loss: nan\n",
      "Epoch 7/30\n",
      "52/52 [==============================] - 75s 1s/sample - loss: nan\n",
      "Epoch 8/30\n",
      "52/52 [==============================] - 78s 1s/sample - loss: nan\n",
      "Epoch 9/30\n",
      "52/52 [==============================] - 77s 1s/sample - loss: nan\n",
      "Epoch 10/30\n",
      "52/52 [==============================] - 80s 2s/sample - loss: nan\n",
      "Epoch 11/30\n",
      "52/52 [==============================] - 79s 2s/sample - loss: nan\n",
      "Epoch 12/30\n",
      "52/52 [==============================] - 73s 1s/sample - loss: nan\n",
      "Epoch 13/30\n",
      "52/52 [==============================] - 74s 1s/sample - loss: nan\n",
      "Epoch 14/30\n",
      "52/52 [==============================] - 74s 1s/sample - loss: nan\n",
      "Epoch 15/30\n",
      "52/52 [==============================] - 74s 1s/sample - loss: nan\n",
      "Epoch 16/30\n",
      "52/52 [==============================] - 73s 1s/sample - loss: nan\n",
      "Epoch 17/30\n",
      "52/52 [==============================] - 76s 1s/sample - loss: nan\n",
      "Epoch 18/30\n",
      "52/52 [==============================] - 76s 1s/sample - loss: nan\n",
      "Epoch 19/30\n",
      "52/52 [==============================] - 77s 1s/sample - loss: nan\n",
      "Epoch 20/30\n",
      "52/52 [==============================] - 69s 1s/sample - loss: nan\n",
      "Epoch 21/30\n",
      "52/52 [==============================] - 73s 1s/sample - loss: nan\n",
      "Epoch 22/30\n",
      "52/52 [==============================] - 69s 1s/sample - loss: nan\n",
      "Epoch 23/30\n",
      "52/52 [==============================] - 72s 1s/sample - loss: nan\n",
      "Epoch 24/30\n",
      "52/52 [==============================] - 69s 1s/sample - loss: nan\n",
      "Epoch 25/30\n",
      "52/52 [==============================] - 68s 1s/sample - loss: nan\n",
      "Epoch 26/30\n",
      "52/52 [==============================] - 68s 1s/sample - loss: nan\n",
      "Epoch 27/30\n",
      "52/52 [==============================] - 71s 1s/sample - loss: nan\n",
      "Epoch 28/30\n",
      "52/52 [==============================] - 76s 1s/sample - loss: nan\n",
      "Epoch 29/30\n",
      "52/52 [==============================] - 78s 1s/sample - loss: nan\n",
      "Epoch 30/30\n",
      "52/52 [==============================] - 80s 2s/sample - loss: nan\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "EPOCHS = 30\n",
    "\n",
    "history = vae.fit( X_train, Y_train, BATCH_SIZE, EPOCHS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/grape/opt/anaconda3/lib/python3.7/site-packages/matplotlib/image.py:397: UserWarning: Warning: converting a masked element to nan.\n",
      "  dv = (np.float64(self.norm.vmax) -\n",
      "/Users/grape/opt/anaconda3/lib/python3.7/site-packages/matplotlib/image.py:398: UserWarning: Warning: converting a masked element to nan.\n",
      "  np.float64(self.norm.vmin))\n",
      "/Users/grape/opt/anaconda3/lib/python3.7/site-packages/matplotlib/image.py:405: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_min = np.float64(newmin)\n",
      "/Users/grape/opt/anaconda3/lib/python3.7/site-packages/matplotlib/image.py:410: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_max = np.float64(newmax)\n",
      "<string>:6: UserWarning: Warning: converting a masked element to nan.\n",
      "/Users/grape/opt/anaconda3/lib/python3.7/site-packages/numpy/ma/core.py:711: UserWarning: Warning: converting a masked element to nan.\n",
      "  data = np.array(a, copy=False, subok=subok)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABG0AAADnCAYAAACkCqtqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAIQUlEQVR4nO3dQW7bOBiAUWnQIyTr8SF6/xMkd2jXzR04qwLNjI3EHbv6SL+3NgTCPwjYH0RpH2NsAAAAALT8dfQCAAAAAPgv0QYAAAAgSLQBAAAACBJtAAAAAIJEGwAAAIAg0QYAAAAg6Ms1H356ehqn0+lOS+GSb9++bW9vb/strmWGx3l9fX0bYzzf4lrmeAx7cQ324vzsxTXYi/OzF9dgL87PXlzDpb14VbQ5nU7by8vL7VbFp3z9+vVm1zLD4+z7/v1W1zLHY9iLa7AX52cvrsFenJ+9uAZ7cX724hou7UXHowAAAACCRBsAAJjEvt/kBAQAkxBtAABgEmOMo5cAwB8k2gAAAAAEiTYAMBFHIwAAmu7xO020AYCJOBoBANB0j99pog0AAABAkGgDXMXRDAAAgPNu/X9JtAGu4mgGAADAebf+vyTaAECYu9sAAB6XaAMAYe5ugzUIsAD8DtEGAADuTIAF4HeINgAAAABBog0AAABAkGgDAAAAECTaAAAAAPymez5sXrT5wM8v3xP/AQAAgH+758PmRZsP/PzyPfEfLhM1AQAAbk+0Af43URMAAOD2RBsAAACAINEGAAAAICgbbTwjAwAAAHhk2WjjGRkAAADAI8tGGwAAAIBHJtoAAAAABIk2AAAAAEGiDQAAAMAZR78kSbQBAAAAOOPolySJNgAAAABBog0A3MnRt9MCADA30QYA7uTo22kBAJibaAMAAAAQJNoAAAAABIk2AAAAAEGiDQAAAECQaAMAAADwi8pbQEUbAAAAgF9U3gIq2gAAAAAEiTYAAAAAQaINAAAAQJBoAwAAABAk2gAAAAAEiTYAAAAAQaINAAAAQJBoAwAAABAk2gAAAABs27bv+9FLeEe0AQAAANi2bYxx9BLeEW0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgCAh7bv+9FLAICzRBsAAB7aGOPoJQDAWaINAAAAQJBoAwAAABAk2gAAAEvwfCJgNaINAACwBM8nAlYj2gAAAAAEiTYAAECOo07wOOz3y0QbAAAgx1EneBz2+2WiDQAAAECQaAMAAAAQJNoAAAAABIk2AAAAAEGiDQAAAHzAG444gmgDAAAAH/CGI44g2gAAAAAEiTYAAAAAQaINAAAAQJBoAwAAABAk2gAAAAAEiTYAAAAAQaINAMAn7ft+9BIAgAci2gAAfNIY4+glAAAPRLQBAAAAruYO1PsTbQAAAICruQP1/kQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAASPD6YID3RBsAACDB64MB3hNtAAAAAIJEGwAAAIAg0SbMmV4AAAB4XKJNmDO9AAAA8Lj2a8LAvu8/tm37fr/lcMHfY4znW1zIDA9ljvMzwzWY4/zMcA3mOD8zXIM5zs8M13B2jldFGwAAAAD+DMejAAAAAIJEGwAAAIAg0QYAAAAgSLQBAAAACBJtAAAAAIJEGwAAAIAg0QYAAAAgSLQBAAAACBJtAAAAAIJEGwAAAIAg0QYAAAAgSLQBAAAACBJtAAAAAIJEGwAAAIAg0QYAAAAgSLQBAAAACBJtAAAAAIJEGwAAAIAg0QYAAAAgSLQBAAAACBJtAAAAAIJEGwAAAICgL9d8+OnpaZxOpzsthUteX1/fxhjPt7iWGR7HHOdnhmswx/mZ4RrMcX5muAZznJ8ZruHSHK+KNqfTaXt5ebndqviUfd+/3+paZngcc5yfGa7BHOdnhmswx/mZ4RrMcX5muIZLc3Q8CgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgCDRBgAAACBItAEAAAAIEm0AAAAAgkQbAAAAgKB9jPH5D+/7j23bvt9vOVzw9xjj+RYXMsNDmeP8zHAN5jg/M1yDOc7PDNdgjvMzwzWcneNV0QYAAACAP8PxKAAAAIAg0QYAAAAgSLQBAAAACBJtAAAAAIJEGwAAAIAg0QYAAAAgSLQBAAAACBJtAAAAAIJEGwAAAICgfwCF2aKKws8TaQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoded_img = vae.predict( X_test )\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir( currDir )\n",
    "\n",
    "n = 10\n",
    "plt.figure( figsize = ( 20, 4 ) )\n",
    "for i in range( n ):\n",
    "\tax = plt.subplot( 2, n, i + 1 )\n",
    "\tplt.imshow( X_test[i].reshape( SIZE, SIZE ) )\n",
    "\tplt.gray()\n",
    "\n",
    "\tax.get_xaxis().set_visible( False )\n",
    "\tax.get_yaxis().set_visible( False )\n",
    "\n",
    "\tax = plt.subplot( 2, n, n + i + 1 )\n",
    "\tplt.imshow( decoded_img[i].reshape( SIZE, SIZE ) )\n",
    "\tplt.gray()\n",
    "\n",
    "\tax.get_xaxis().set_visible( False )\n",
    "\tax.get_yaxis().set_visible( False )\n",
    "\n",
    "plt.savefig( 'Result.png', dpi = 300 )\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
