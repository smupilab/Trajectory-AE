{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import convertImage\n",
    "\n",
    "SIZE = 512\n",
    "\n",
    "trajectoryAugmentataionDir = '/Users/graph/GitHub/Trajectory-Augmentation/'\n",
    "trajectoryDataDir = '/Users/grape/GitHub/Trajectory_Data/'\n",
    "\n",
    "currDir = trajectoryAugmentataionDir + 'script/'\n",
    "dataDir = trajectoryDataDir + 'VirtualData/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir( dataDir )\n",
    "files = glob.glob( '*csv' )\n",
    "\n",
    "trainSize = int( len( files ) * 0.8 )\n",
    "trainFiles, testFiles = files[ : trainSize], files[trainSize : ]\n",
    "\n",
    "X_train, Y_train = [ ], [ ]\n",
    "for file in trainFiles:\n",
    "\tcsv_file = pd.read_csv( file, names = [ 'lat', 'long', 'num' ], header = None )\n",
    "\tmaxmin = convertImage.coorMaxMin( csv_file )\n",
    "\tX_train.append( convertImage.map2Image_remove( *maxmin, csv_file ) )\n",
    "\tY_train.append( convertImage.map2Image( *maxmin, csv_file ) )\n",
    "\n",
    "X_test = [ ]\n",
    "for file in testFiles:\n",
    "\tcsv_file = pd.read_csv( file, names = [ 'lat', 'long', 'num' ], header = None )\n",
    "\tmaxmin = convertImage.coorMaxMin( csv_file )\n",
    "\tX_test.append( convertImage.map2Image_remove( *maxmin, csv_file ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = np.array( X_train ), np.array( Y_train )\n",
    "X_test = np.array( X_test )\n",
    "\n",
    "X_train = X_train / 255.\n",
    "Y_train = Y_train / 255.\n",
    "X_test = X_test / 255.\n",
    "\n",
    "X_train = np.reshape( X_train, ( len( X_train ), SIZE, SIZE, 1 ) )\n",
    "Y_train = np.reshape( Y_train, ( len( Y_train ), SIZE, SIZE, 1 ) )\n",
    "X_test = np.reshape( X_test, ( len( X_test ), SIZE, SIZE, 1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf; tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def ComputeLatent( x ):\n",
    "\tmu, sigma = x\n",
    "\teps = K.random_normal( shape = ( K.shape( mu )[0], K.int_shape( mu )[1] ) )\n",
    "\n",
    "\treturn mu + K.exp( sigma / 2 ) * eps\n",
    "\n",
    "latent = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/grape/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "encoder_input = layers.Input( shape = ( SIZE, SIZE, 1 ) )\n",
    "encoder_conv = layers.Conv2D( 128, 3, 2, 'same', activation = 'relu' )( encoder_input )\n",
    "encoder_conv = layers.Conv2D( 256, 3, 2, 'same', activation = 'relu' )( encoder_conv )\n",
    "\n",
    "encoder = layers.Flatten()( encoder_conv )\n",
    "\n",
    "mu = layers.Dense( latent )( encoder )\n",
    "sigma = layers.Dense( latent )( encoder )\n",
    "\n",
    "latent_space = layers.Lambda( ComputeLatent, output_shape = ( latent, ) )( [ mu, sigma ] )\n",
    "\n",
    "conv_shape = K.int_shape( encoder_conv )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = layers.Input( shape = ( latent, ) )\n",
    "\n",
    "units = conv_shape[1] * conv_shape[2] * conv_shape[3]\n",
    "decoder = layers.Dense( units, 'relu' )( decoder_input )\n",
    "decoder = layers.Reshape( ( conv_shape[1], conv_shape[2], conv_shape[3] ) )( decoder )\n",
    "\n",
    "decoder_conv = layers.Conv2DTranspose( 256, 3, 2, 'same', activation = 'relu' )( decoder )\n",
    "decoder_conv = layers.Conv2DTranspose( 128, 3, 2, 'same', activation = 'relu' )( decoder_conv )\n",
    "decoder_output = layers.Conv2DTranspose( 1, 3, padding = 'same', activation = 'sigmoid' )( decoder_conv )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 128 1280        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 256 295168      conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 4194304)      0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            8388610     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            8388610     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 2)            0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 17,073,668\n",
      "Trainable params: 17,073,668\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4194304)           12582912  \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 256, 256, 256)     590080    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 512, 512, 128)     295040    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 512, 512, 1)       1153      \n",
      "=================================================================\n",
      "Total params: 13,469,185\n",
      "Trainable params: 13,469,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"VAE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 512, 512, 1)]     0         \n",
      "_________________________________________________________________\n",
      "Encoder (Model)              (None, 2)                 17073668  \n",
      "_________________________________________________________________\n",
      "Decoder (Model)              (None, 512, 512, 1)       13469185  \n",
      "=================================================================\n",
      "Total params: 30,542,853\n",
      "Trainable params: 30,542,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = keras.models.Model( encoder_input, latent_space, name = 'Encoder' )\n",
    "decoder = keras.models.Model( decoder_input, decoder_output, name = 'Decoder' )\n",
    "\n",
    "vae = keras.models.Model( encoder_input, decoder( encoder( encoder_input ) ), name = 'VAE' )\n",
    "\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_Reconstruction_Loss( true, pred ):\n",
    "\treconstruction_loss = keras.losses.binary_crossentropy( K.flatten( true ), K.flatten( pred ) ) * SIZE * SIZE\n",
    "\n",
    "\tkl_loss = 1 + sigma - K.square( mu ) - K.exp( sigma )\n",
    "\tkl_loss = K.sum( kl_loss, axis = -1 )\n",
    "\tkl_loss *= -0.5\n",
    "\n",
    "\treturn K.mean( reconstruction_loss + kl_loss )\n",
    "\n",
    "vae.compile( 'adam', KL_Reconstruction_Loss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "EPOCHS = 30\n",
    "\n",
    "history = vae.fit( X_train, Y_train, BATCH_SIZE, EPOCHS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_img = vae.predict( X_test )\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir( currDir )\n",
    "\n",
    "n = 10\n",
    "plt.figure( figsize = ( 20, 4 ) )\n",
    "for i in range( n ):\n",
    "\tax = plt.subplot( 2, n, i + 1 )\n",
    "\tplt.imshow( X_test[i].reshape( SIZE, SIZE ) )\n",
    "\tplt.gray()\n",
    "\n",
    "\tax.get_xaxis().set_visible( False )\n",
    "\tax.get_yaxis().set_visible( False )\n",
    "\n",
    "\tax = plt.subplot( 2, n, n + i + 1 )\n",
    "\tplt.imshow( decoded_img[i].reshape( SIZE, SIZE ) )\n",
    "\tplt.gray()\n",
    "\n",
    "\tax.get_xaxis().set_visible( False )\n",
    "\tax.get_yaxis().set_visible( False )\n",
    "\n",
    "plt.savefig( 'Result.png', dpi = 300 )\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
