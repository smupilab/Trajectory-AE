{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Taejin1221/Lab_Experiment/blob/main/Trajectory_Clustering/Trajectory_Clustering_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKU6FnEmY7fH"
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CtN6Kze-_XI0"
   },
   "outputs": [],
   "source": [
    "import os, cv2, glob, time\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o50o01S-ltzx"
   },
   "source": [
    "# Set Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "Rmyk0hcfBIl8",
    "outputId": "22d2633f-4d58-4a68-c04c-562fd9247a79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Constants\n",
    "WIDTH, HEIGHT = 64, 64\n",
    "RATIO = WIDTH / 256\n",
    "\n",
    "EXPERIMENT_DATA = {\n",
    "    'name' : 'Trajectory_Clusetring(Vessel_Method)',\n",
    "    'number' : '4',\n",
    "    'date' : '02-24-2022',\n",
    "    'description' : 'Train Autoencoder model with 64x64 images\\n'\n",
    "    }\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "os.chdir(ROOT_DIR)\n",
    "\n",
    "GEOLIFE_DIR = os.path.join('C:\\\\', 'Dataset', 'Geolife')\n",
    "DATA_DIR = os.path.join(GEOLIFE_DIR, 'Data')\n",
    "IMAGE_DIR = os.path.join(GEOLIFE_DIR, 'Image_Files')\n",
    "\n",
    "if ( 'Results' not in os.listdir() ):\n",
    "    os.mkdir( 'Results' )\n",
    "RESULT_DIR = os.path.join( 'C:\\\\', 'GitHub', 'Lab_Experiment', 'Results')\n",
    "\n",
    "plt.gray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tN2e3qmxZHb9"
   },
   "source": [
    "# Load and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(IMAGE_DIR)\n",
    "file_names = sorted(glob.glob('*png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "for file in file_names:\n",
    "    src = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    dst = cv2.resize(src, dsize=(0, 0), fx=RATIO, fy=RATIO, interpolation=cv2.INTER_LINEAR)\n",
    "    train_images.append(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64)\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(train_images[0])\n",
    "plt.show()\n",
    "print(train_images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "W4jqhOghcnAW"
   },
   "outputs": [],
   "source": [
    "X_train = np.array( train_images ).astype( 'float32' ) / 255.\n",
    "X_train = np.reshape( X_train, ( -1, HEIGHT, WIDTH, 1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZmcQe3t0X3Qh",
    "outputId": "229e7bb4-cf3a-4439-b6de-eb5430030273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18670, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "print( X_train.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "af, pd = 'relu', 'same' # activation function and padding value\n",
    "\n",
    "encode_input = layers.Input( ( HEIGHT, WIDTH, 1 ) )\n",
    "x = layers.Conv2D( 32, ( 3, 3 ), activation = af, padding = pd )( encode_input )\n",
    "x = layers.MaxPooling2D( ( 2, 2 ), padding = pd )( x )\n",
    "\n",
    "x = layers.Conv2D( 32, ( 3, 3 ), activation = af, padding = pd )( x )\n",
    "x = layers.MaxPooling2D( ( 2, 2 ), padding = pd )( x )\n",
    "\n",
    "x = layers.Conv2D( 16, ( 3, 3 ), activation = af, padding = pd )( x )\n",
    "x = layers.MaxPooling2D( ( 2, 2 ), padding = pd )( x )\n",
    "\n",
    "x = layers.Conv2D( 16, ( 3, 3 ), activation = af, padding = pd )( x )\n",
    "x = layers.MaxPooling2D( ( 2, 2 ), padding = pd )( x )\n",
    "\n",
    "feature_map_shape = x.shape\n",
    "flatten_size = feature_map_shape[1] * feature_map_shape[2] * feature_map_shape[3]\n",
    "\n",
    "x = layers.Flatten()( x )\n",
    "encode_output = layers.Dense( flatten_size , activation = af )( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 64, 64, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 82,304\n",
      "Trainable params: 82,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = keras.Model( encode_input, encode_output, name = 'Encoder' )\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_input = layers.Input( ( flatten_size ) )\n",
    "\n",
    "x = layers.Dense( flatten_size, activation = af )( decode_input )\n",
    "x = layers.Reshape( feature_map_shape[1:] )( x )\n",
    "\n",
    "x = layers.Conv2DTranspose( 16, ( 3, 3 ), activation = af, padding = pd )( x )\n",
    "x = layers.UpSampling2D( ( 2, 2 ) )( x )\n",
    "\n",
    "x = layers.Conv2DTranspose( 16, ( 3, 3 ), activation = af, padding = pd )( x )\n",
    "x = layers.UpSampling2D( ( 2, 2 ) )( x )\n",
    "\n",
    "x = layers.Conv2DTranspose( 32, ( 3, 3 ), activation = af, padding = pd )( x )\n",
    "x = layers.UpSampling2D( ( 2, 2 ) )( x )\n",
    "\n",
    "x = layers.Conv2DTranspose( 32, ( 3, 3 ), activation = af, padding = pd )( x )\n",
    "x = layers.UpSampling2D( ( 2, 2 ) )( x )\n",
    "\n",
    "decode_output = layers.Conv2DTranspose( 1, ( 3, 3 ), activation = af, padding = pd )( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 256)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 4, 4, 16)          2320      \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 64, 64, 1)         289       \n",
      "=================================================================\n",
      "Total params: 84,609\n",
      "Trainable params: 84,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = keras.Model( decode_input, decode_output, name = 'Decoder' )\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Auto_Encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 1)]       0         \n",
      "_________________________________________________________________\n",
      "Encoder (Functional)         (None, 256)               82304     \n",
      "_________________________________________________________________\n",
      "Decoder (Functional)         (None, 64, 64, 1)         84609     \n",
      "=================================================================\n",
      "Total params: 166,913\n",
      "Trainable params: 166,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "auto_encoder = keras.Model( encode_input, decoder( encoder( encode_input ) ), name = 'Auto_Encoder' )\n",
    "auto_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_encoder.compile( 'adam', loss = 'mse' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 300\n",
    "BATCH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "73/73 [==============================] - 10s 45ms/step - loss: 0.0028\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0027\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0026\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0025\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0024\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0024\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0024\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0023\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0023\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0023\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0023\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0023\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0022\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0022\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0022\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0022\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0022\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0022\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0022\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0022\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0022\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0021\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0021\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0021\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0021\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0021\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0021\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0021\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0021\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0021\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0021\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0021\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0021\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0021\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0021\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0021\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0020\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0020\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0020\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0020\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0020\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 3s 39ms/step - loss: 0.0018\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0019\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0019\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 3s 39ms/step - loss: 0.0019\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0019\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0018\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0018\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0018\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 3s 39ms/step - loss: 0.0018\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 3s 39ms/step - loss: 0.0018\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 3s 39ms/step - loss: 0.0018\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 3s 39ms/step - loss: 0.0018\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 3s 39ms/step - loss: 0.0018\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 3s 39ms/step - loss: 0.0018\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 3s 39ms/step - loss: 0.0018\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 3s 39ms/step - loss: 0.0018\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 3s 39ms/step - loss: 0.0018\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0018\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0018\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0017\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0018\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0017\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 243/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 244/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 245/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 246/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 247/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 248/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 249/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 250/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 251/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 252/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 253/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 254/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 255/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 256/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 257/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 258/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 259/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 260/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 261/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 262/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 263/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 264/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 265/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 266/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 267/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 268/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 269/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 270/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 271/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 272/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 273/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 274/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0017\n",
      "Epoch 275/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 276/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 277/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 278/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 279/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 280/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 281/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 282/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0017\n",
      "Epoch 283/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 284/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 285/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 286/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 287/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 288/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 289/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 290/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 291/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 292/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 293/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 294/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 295/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 296/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 297/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 298/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 299/300\n",
      "73/73 [==============================] - 3s 38ms/step - loss: 0.0017\n",
      "Epoch 300/300\n",
      "73/73 [==============================] - 3s 37ms/step - loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "history = auto_encoder.fit( X_train, X_train, epochs = EPOCH, batch_size = BATCH  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "os.chdir( RESULT_DIR )\n",
    "\n",
    "new_result_dir = f\"{EXPERIMENT_DATA['name']}_{EXPERIMENT_DATA['date']}_Results\"\n",
    "os.mkdir( new_result_dir )\n",
    "os.chdir( new_result_dir )\n",
    "\n",
    "encoder.save('encoder.h5')\n",
    "decoder.save('decoder.h5')\n",
    "auto_encoder.save('auto_encoder.h5')\n",
    "\n",
    "with open( 'Description.txt', 'w' ) as f:\n",
    "    f.write( EXPERIMENT_DATA['description'] )\n",
    "    f.write('\\n')\n",
    "    f.write(f'Image size: {HEIGHT} x {WIDTH}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIZdFM_NZEkP"
   },
   "source": [
    "# Convert image data into low dimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18670, 64, 64, 1)\n",
      "(18670, 256)\n"
     ]
    }
   ],
   "source": [
    "low_dimension_data, prevIdx = [ ], 0\n",
    "for i in range(0, len(X_train), 1000):\n",
    "    low_dimension_data.extend(encoder(X_train[prevIdx:i]))\n",
    "    prevIdx = i\n",
    "low_dimension_data.extend(encoder(X_train[prevIdx:]))\n",
    "\n",
    "low_dimension_data = np.array(low_dimension_data)\n",
    "print(X_train.shape)\n",
    "print(low_dimension_data.shape)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO5xGngAUpHeRi8s/W7TW7e",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1-NXO5VFyOpZpe4_IfU-y1nyC8H5ezAYj",
   "name": "Trajectory_Clustering_16.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
